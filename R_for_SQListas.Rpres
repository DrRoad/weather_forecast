```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE)
#opts_chunk$set(out.width='750px', dpi=200)
```
<style>
.small-code pre code {
  font-size: 1em;
}
.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
}
</style>



Data %>% Power %>% R
========================================================
width: 1440
incremental:true 
You ready?

R
========================================================
class:small-code

&nbsp;
  
- a powerful open source programming language 
- available in the database as Oracle R Enterprise
- that lets you do virtually anything...


Especially (but not only)
========================================================
class:small-code

&nbsp;
  
- Statistics
- Machine Learning
- Visualization
- Presentation (evidently)


Fine.
========================================================
class:small-code

&nbsp;
  
But I'm a SQL girl.  
  
Now I gotta learn something totally new?


Don't fear
========================================================
class:small-code

&nbsp;

Enter  

  
![](hadley.jpg)
  
_"All tidy datasets are alike, every untidy dataset is untidy in its own way."_<br />
(Hadley Wickham)


The tidyverse
========================================================
class:small-code

&nbsp;
  
```{r}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
```




But we're not just gonna do R syntax.
========================================================
class:small-code

&nbsp;
  
Let's look at some real data!


Everyone talks about the weather
========================================================
class:small-code

&nbsp;
  
I certainly do.


This is what I want for winter.
========================================================
class:small-code

&nbsp;

![](snow.jpg)

This is what I get.
========================================================
class:small-code

&nbsp;

![](rain.jpg)



Let's try to find out about the future
========================================================
class:small-code

&nbsp;
  
- Berkeley Earth Surface Temperature Study
  + https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)
  + monthly averages, 1743-2013
- Weather data from weather station Munich airport
  - retrieved from www.wunderground.com
  - daily averages, 1997-2015


Berkeley Earth global land temperatures
========================================================
class:small-code

&nbsp;
  
```{r}
df <- read_csv('data/GlobalLandTemperaturesByCity.csv')
head(df,3)
```


Before we even start
========================================================
class:small-code

&nbsp;
  
_Let's get ourselves some nicer variable names._
```{r}
df <- rename(df,
             avg_temp = AverageTemperature,
             avg_temp_95p = AverageTemperatureUncertainty,
             city = City,
             country = Country,
             lat = Latitude,
             long = Longitude)
head(df,3)
```

distinct (SELECT distinct)
========================================================
class:small-code

&nbsp;
  
_First thing I'd like to know: Which locations are available?_
```{r}
head(distinct(df, country), 3)
head(distinct(df, city), 3)
```

filter (WHERE) 
========================================================
class:small-code

&nbsp;
  
_Let's see some Munich data!_
```{r}
head(filter(df, city == 'Munich'), 3)
```

filter (combining predicates)
========================================================
class:small-code

&nbsp;

```{r}
# AND
head(filter(df, city == 'Munich' & year(dt) > 2000), 3)

# OR
head(filter(df, city == 'Munich' | year(dt) > 2000), 3)
```


select (SELECT)
========================================================
class:small-code

&nbsp;
  
_Just concentrate on the important variables._
```{r}
head(select(filter(df, city == 'Munich'), dt, avg_temp, avg_temp_95p), 8)
```

arrange (ORDER BY)
========================================================
class:small-code

&nbsp;
  
_Coldest months ever._
```{r}
head(arrange(select(filter(df, city == 'Munich'), dt, avg_temp), avg_temp), 8)
```

All these parens are starting to be a pain...
========================================================
class:small-code

&nbsp;
  
What if we added still further data processing steps?


Enter: %>%
========================================================
class:small-code

&nbsp;
  
![](pipe.jpg)
  
What you see:  __x %>% f(y)__  
What you get:    __f(x, y)__ 

Coldest months, with the %>%!
========================================================
class:small-code

&nbsp;
  
```{r}
df %>% filter(city == 'Munich') %>% select(dt, avg_temp) %>% arrange(avg_temp) %>% head(8)
```
&nbsp;
_Now that we have %>%, we can tackle more complex statements._

group_by (GROUP BY)
========================================================
class:small-code

&nbsp;
  
_What countries have most measurements?_
```{r}
df %>% group_by(country) %>% summarise(count=n()) %>% arrange(count %>% desc()) %>% head(8)
```


group_by (multiple summaries)
========================================================
class:small-code

&nbsp;
  
_What are the average, min and max monthly temperatures in Germany after 1949?_
```{r}
df %>% filter(country == 'Germany', !is.na(avg_temp), year(dt) > 1949) %>% group_by(month(dt)) %>% summarise(count = n(), avg = mean(avg_temp), min = min(avg_temp), max = max(avg_temp))
```

JOINs: inner_join, left_join, anti_join ...
========================================================
class:small-code

&nbsp;
  
_Let's join the two different data sources on the month column:_
```{r}
daily_1997_2015 <- read_csv('data/munich_1997_2015.csv')
monthly_1997_2015 <- daily_1997_2015 %>% group_by(month = floor_date(daily_1997_2015$day, "month")) %>% summarise(mean_temp = mean(mean_temp))

df_1949 <- df %>% select(dt, avg_temp) %>% filter(year(dt) > 1949)

df_1949 %>% inner_join(monthly_1997_2015, by = c("dt" = "month")) %>% head(3)
```

UNION & friends: union, setdiff, intersect
========================================================
class:small-code

&nbsp;
  
_Union of pre-2016 and 2016 Munich daily weather data._
```{r}
daily_2016 <- read_csv('data/munich_2016.csv')
daily_1997_2015 %>% dplyr::union(daily_2016) %>% arrange(day) %>% head(8)
```

Window functions (1)
========================================================
class:small-code

&nbsp;
  
_5% hottest days in Munich in 2016._
```{r}
 filter(daily_2016, cume_dist(desc(mean_temp)) < 0.05) %>% select(day, mean_temp) %>% arrange(desc(mean_temp))
```

Window functions (2)
========================================================
class:small-code

&nbsp;
  
_Top 3 coldest days in Munich in 2016._

```{r}
 filter(daily_2016, dense_rank(mean_temp) < 4) %>% select(day, mean_temp) %>% arrange(mean_temp)
```

Window functions
========================================================
class:small-code

&nbsp;
  
_Consecutive days where mean temperatures differ by more than 5 degrees._

```{r}
daily_2016 %>% mutate(yesterday_temp = lag(mean_temp)) %>% filter(abs(yesterday_temp - mean_temp) > 5) %>% select(day, mean_temp, yesterday_temp)
```

OK. So we can do all that with R. 
========================================================
class:small-code

&nbsp;
  
How about what we CAN'T do in SQL?


There was this original question about snow.
========================================================
class:small-code

&nbsp;
  
Let's see what we might predict about the future.


The grammar of graphics: visualization with ggplot2
========================================================
class:small-code

&nbsp;
  
_How cold is it in Munich, compared to, say, Bern or Oslo?_  
```{r, echo=FALSE}
library(ggthemes)
```
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
df_cities <- df %>% filter(city %in% c("Munich", "Bern", "Oslo"), year(dt) > 1949, !is.na(avg_temp))
(p_1950 <- ggplot(df_cities, aes(dt, avg_temp, color = city)) + geom_point() + xlab("") + ylab("avg monthly temp") + theme_solarized())
```


Can we see a trend?
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
start_time <- as.Date("1992-01-01")
end_time <- as.Date("2013-08-01")
limits <- c(start_time,end_time)
(p_1992 <- p_1950 + (scale_x_date(limits=limits)) + geom_smooth(se = TRUE))
```


Let's concentrate on Munich.
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
df_munich <- df_cities %>% filter(city == 'Munich')
p_munich_1950 <- ggplot(df_munich, aes(dt, avg_temp)) + geom_point() + xlab("") + ylab("avg monthly temp") + theme_solarized() + geom_smooth()
p_munich_1950
```

Difficult.
========================================================

&nbsp;
  
There might be a trend, or there might not.
  
Of course, there is not just one smoothing algorithm only.  


LOESS (Local Polynomial Regression Fitting) vs. LM (Linear Model)
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
loess <- p_munich_1950 + stat_smooth(method = "loess", colour = "red") + labs(title = 'loess')
lm <- p_munich_1950 + stat_smooth(method = "lm", color = "green") + labs(title = 'lm')
grid.arrange(loess, lm, ncol=2)
```


So?
========================================================

&nbsp;
  
We need to dig deeper and really analyze those time series.


Time series: A quick first glance
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
ts_1950 <- ts(df_munich$avg_temp, start = c(1950,1), end=c(2013,8), frequency = 12)
ts_1997 <- ts(monthly_1997_2015$mean_temp, start = c(1997,1), frequency = 12)
par(mfrow=c(1,2))
plot(ts_1950, main = 'Munich, 1950-2013', ylab = 'avg. monthly temp.')
plot(ts_1997,  main = 'Munich, 1997-2015', ylab = 'avg. monthly temp., aggregated')
par(mfrow=c(1,1))
```


Time series decomposition
========================================================
class:small-code

&nbsp;
  
Time series may be decomposed into different effects:
- trend
- seasonal (if available)
- remainder




Time series decomposition: Berkeley Earth data, 1950-2013
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=6, fig.show='hold', fig.align='center'}
library(stlplus)
fit <- stlplus(ts_1950, s.window="periodic", t.window=37)
plot(fit)
```

Time series decomposition: Munich weather data, 1997-2015
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- stlplus(ts_1997, s.window="periodic", t.window=37)
plot(fit)
```



Exponential Smoothing
========================================================
class:small-code

&nbsp;

- Predicted values at time t+1 are weighted averages of values at times t, t-1, t-2 ...: $\hat{y}_{T+1|T} = \alpha y_T + \alpha(1-\alpha) y_{T-1} + \alpha(1-\alpha)^2 y_{T-2}+ \cdots$
- Can also model trends and seasonal effects (Holt-Winters)

State Space Models
========================================================
class:small-code

&nbsp;
  
- Conceptually equivalent to exponential smoothing
- BUT also generate prediction intervals!
- http://www.exponentialsmoothing.net/
- R: __ets()__ function in __forecast__ package

ets()
========================================================
class:small-code

&nbsp;
  
- When called without parameters, __ets()__ determines a suitable model itself
- Using maximum likelihood estimation

ets():  Berkeley Earth data, 1950-2013
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
library(forecast)
fit <- ets(ts_1950)
summary(fit)
```

ets():  Berkeley Earth data, 1950-2013
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
# Plot the smoothed components - no trend!
plot(fit)
```

ets():  Berkeley Earth data, 1950-2013
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
# Forecast next 3 years
plot(forecast(fit, h=36))
```



ets(): Munich weather data, 1997-2015
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- ets(ts_1997) 
summary(fit)
```



ets(): Munich weather data, 1997-2015
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
# Plot the smoothed components - no trend!
plot(fit)
```


ets(): Munich weather data, 1997-2015
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
# Forecast next 3 years
plot(forecast(fit, h=36))
```


ARIMA
========================================================
class:small-code

&nbsp;
  
- *__AR(p)__*:  
autoregressive: $$y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \dots + \phi_{p}y_{t-p} + e_{t}$$
- *__I(d)__*:  
number of times differencing has to be applied to obtain a stationary series
- *__MA(q)__*:  
moving average: $$y_{t} = c + e_t + \theta_{1}e_{t-1} + \theta_{2}e_{t-2} + \dots + \theta_{q}e_{t-q}$$

&nbsp;

_Stationarity: If a time series $y_{t}$ is stationary, then for all $s$, the distribution of ($y_{t}$,…, $y_{t+s}$) does not depend on $t$._


Stationarity: ACF and PACF
========================================================
class:small-code

&nbsp;
Berkeley Earth data, 1950-2013
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
tsdisplay(ts_1950)
```

Stationarity: ACF and PACF
========================================================
class:small-code

&nbsp;
Munich weather data, 1997-2015
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
tsdisplay(ts_1997)
```


Cyclostationary process
========================================================
class:small-code

&nbsp;

Mean and variance are constant for seasonally corresponding measurements.  


How do we decide which p,d,q to use for ARIMA?
========================================================
class:small-code

&nbsp;
  
Just use auto.arima().  
(But see later.)

ARIMA: Berkeley Earth data, 1950-2013
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- auto.arima(ts_1950)
summary(fit)
```


ARIMA: Munich weather data, 1997-2015
========================================================
class:small-code

&nbsp;
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- auto.arima(ts_1997)
summary(fit)
```



Let's get forecasting!
========================================================
class:small-code

&nbsp;
  
Wait. 
 
ARIMA forecasts are based on the assumption that residuals are uncorrelated and normally distributed.


Residuals: Autocorrelation
========================================================
class:small-code

&nbsp;

Berkeley Earth data, 1950-2013 
  
```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- auto.arima(ts_1950)
res <- fit$residuals
acf <- acf(res, main='Autocorrelation of residuals')
```


Allowing for more parameters: Berkeley Earth data, 1950-2013 
========================================================
class:small-code

&nbsp;

```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- auto.arima(ts_1950, max.order = 10, stepwise=FALSE)
summary(fit)
```

Forecast: Berkeley Earth data, 1950-2013 
========================================================
class:small-code

&nbsp;

```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
plot(forecast(fit,h=36),include=80)
```



Allowing for more parameters: Munich weather data, 1997-2015 
========================================================
class:small-code

&nbsp;

```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
fit <- auto.arima(ts_1997, max.order = 10, stepwise=FALSE) 
summary(fit)
```


Forecast: Munich weather data, 1997-2015 
========================================================
class:small-code

&nbsp;

```{r, fig.width=18, fig.height=5, fig.show='hold', fig.align='center'}
plot(forecast(fit,h=36),include=80)
```


Oops
========================================================
class:small-code

&nbsp;

What happened?

- ARIMA has problems with too few data points
- ARIMA works better with the longer series
- while ETS handles the shorter series better
- larger uncertainty intervals with ARIMA than with ETS


Beyond the weather ...
========================================================
class:small-code

&nbsp;

- Forecasting is required (and done!) everywhere
- R gives you all the tools you need
- you need to know what you're doing though!


Data Science
========================================================
class:small-code

&nbsp;

... is about more than just having data.

It needs (a bit of) science get to the insights!


Let's start doing some data science
========================================================
class:small-code

&nbsp;

Thank you!